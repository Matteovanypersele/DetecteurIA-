The idea is to builds an AI‑text detector that use two complementary signals: (i) state‑of‑the‑art NLP features—frozen RoBERTa embeddings feeding a lightweight classifier in order to judge the finished text, and (ii) keystroke‑log metadata (pauses, bursts, insertions, deletions) that capture the writing process itself. The intuition is that  large language models can evade product‑only detectors through paraphrase or back‑translation, while the fine‑grained dynamics of human typing are hard to fake, combining both views should yields a more robust detector applicable across diverse genres, from homework essays to recruitment letters. This approach was an intuition that we had since the begining of the class and was really emphasized with the paper : https://doi.org/10.5281/zenodo.12729864 and its data https://github.com/scrosseye/ai_detection_keystroke_logs/blob/main/ai_detect_keystroke_logging_data_anon_github.csv
