{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05a6dd16-1ff6-496c-8e69-dfecce564552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9685 sha256=211a60b4c7b23ee460e87a1750d37c6fcfa721572d6bd665bf3534efa22c8669\n",
      "  Stored in directory: /home/onyxia/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a392e8a-cb38-4e99-ad17-546c70448f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.17.0)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.29.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.29.2-py3-none-any.whl (468 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: tzdata, safetensors, regex, pandas, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.29.2 pandas-2.2.3 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.0 transformers-4.49.0 tzdata-2025.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07b9f521-2b62-472d-889a-f46730dd7c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier enrichi sauvegardé : OpenLLMText_Human/valid-dirty_enriched.jsonl\n",
      "Fichier enrichi sauvegardé : OpenLLMText_Human/valid-dirty_enriched_enriched.jsonl\n",
      "Fichier enrichi sauvegardé : OpenLLMText_Human/train-dirty_enriched.jsonl\n",
      "Fichier enrichi sauvegardé : OpenLLMText_Human/train-dirty_enriched_enriched.jsonl\n",
      "Fichier enrichi sauvegardé : OpenLLMText_Human/test-dirty_enriched_enriched.jsonl\n",
      "Fichier enrichi sauvegardé : OpenLLMText_Human/test-dirty_enriched.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Définir le dossier contenant les fichiers JSONL à modifier\n",
    "dataset_folders = [\n",
    "    \"OpenLLMText_Human\"\n",
    "]\n",
    "\n",
    "# Fonction pour ajouter les nouvelles métadonnées au champ \"extra\"\n",
    "def enrich_data(file_path, text_source):\n",
    "    updated_data = []\n",
    "    \n",
    "    # Charger le fichier JSONL ligne par ligne\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    num_samples = len(lines)  # Nombre d'exemples dans le fichier\n",
    "\n",
    "    # Générer les nouvelles métadonnées\n",
    "    enriched_metadata = {\n",
    "        \"text_source\": [text_source] * num_samples,\n",
    "        \"time_spent_per_word\": np.random.uniform(0.1, 0.5, num_samples),\n",
    "        \"num_deletions\": np.random.randint(5, 20, num_samples),\n",
    "        \"num_rewrites\": np.random.randint(3, 15, num_samples),\n",
    "        \"copy_paste_usage\": np.random.uniform(0, 0.3, num_samples),\n",
    "        \"pauses\": np.random.uniform(1, 10, num_samples),\n",
    "        \"sentence_reordering\": np.random.uniform(0.1, 0.5, num_samples),\n",
    "    }\n",
    "\n",
    "    # Modifier chaque ligne du fichier JSONL\n",
    "    for i, line in enumerate(lines):\n",
    "        data = json.loads(line.strip())  # Convertir en dict\n",
    "        data[\"extra\"].update({  # Ajouter les nouvelles informations\n",
    "            \"text_source\": enriched_metadata[\"text_source\"][i],\n",
    "            \"time_spent_per_word\": float(enriched_metadata[\"time_spent_per_word\"][i]),\n",
    "            \"num_deletions\": int(enriched_metadata[\"num_deletions\"][i]),\n",
    "            \"num_rewrites\": int(enriched_metadata[\"num_rewrites\"][i]),\n",
    "            \"copy_paste_usage\": float(enriched_metadata[\"copy_paste_usage\"][i]),\n",
    "            \"pauses\": float(enriched_metadata[\"pauses\"][i]),\n",
    "            \"sentence_reordering\": float(enriched_metadata[\"sentence_reordering\"][i])\n",
    "        })\n",
    "        updated_data.append(data)\n",
    "\n",
    "    # Sauvegarder le fichier modifié\n",
    "    new_file_path = file_path.replace(\".jsonl\", \"_enriched.jsonl\")\n",
    "    with open(new_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for entry in updated_data:\n",
    "            f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "    print(f\"Fichier enrichi sauvegardé : {new_file_path}\")\n",
    "\n",
    "# Appliquer la transformation à tous les fichiers JSONL\n",
    "for folder in dataset_folders:\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".jsonl\"):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            enrich_data(file_path, text_source=folder.replace(\"OpenLLMText_\", \"\"))  # Déduire la source du texte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c9574fc-951f-44b6-9f95-732bf01ecf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Données chargées avec séparation des métadonnées\n",
      "                                                text  label  \\\n",
      "0  Wednesday, April 6th, 2016\\n\\n\"It is shameful ...      0   \n",
      "1  SAN FRANCISCO (BCN)— A civil lawsuit filed Wed...      0   \n",
      "2  Automated wheel changer. Image: Rio Tinto.\\n\\n...      0   \n",
      "3  A Washington Post reporter admitted that Presi...      0   \n",
      "4  An a-scientific paper, poor contribution of NG...      0   \n",
      "\n",
      "   meta_time_spent_per_word  meta_num_deletions  meta_num_rewrites  \\\n",
      "0                  0.142871                  14                 10   \n",
      "1                  0.488851                   8                 10   \n",
      "2                  0.260543                  14                 13   \n",
      "3                  0.107372                  13                  3   \n",
      "4                  0.161164                   8                 10   \n",
      "\n",
      "   meta_copy_paste_usage  meta_pauses  meta_sentence_reordering  \n",
      "0               0.199902     8.300962                  0.182648  \n",
      "1               0.268167     5.216166                  0.303016  \n",
      "2               0.088837     8.797998                  0.145323  \n",
      "3               0.140421     7.013374                  0.384291  \n",
      "4               0.197570     1.396340                  0.333739  \n",
      "   meta_time_spent_per_word  meta_num_deletions  meta_num_rewrites  \\\n",
      "0                  0.142871                14.0               10.0   \n",
      "1                  0.488851                 8.0               10.0   \n",
      "2                  0.260543                14.0               13.0   \n",
      "3                  0.107372                13.0                3.0   \n",
      "4                  0.161164                 8.0               10.0   \n",
      "\n",
      "   meta_copy_paste_usage  meta_pauses  meta_sentence_reordering  \n",
      "0               0.199902     8.300962                  0.182648  \n",
      "1               0.268167     5.216166                  0.303016  \n",
      "2               0.088837     8.797998                  0.145323  \n",
      "3               0.140421     7.013374                  0.384291  \n",
      "4               0.197570     1.396340                  0.333739  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Dossiers contenant les fichiers enrichis\n",
    "dataset_folders = {\n",
    "    \"Human\": \"OpenLLMText_Human\",\n",
    "    \"ChatGPT\": \"OpenLLMText_ChatGPT\",\n",
    "}\n",
    "\n",
    "data = []\n",
    "\n",
    "# Charger uniquement Human et ChatGPT\n",
    "for source, folder in dataset_folders.items():\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\"_enriched.jsonl\"):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    entry = json.loads(line.strip())\n",
    "                    text = entry[\"text\"]\n",
    "                    extra = entry[\"extra\"]\n",
    "\n",
    "                    # Créer un dictionnaire avec le texte, le label et les métadonnées séparées\n",
    "                    data.append({\n",
    "                        \"text\": text,\n",
    "                        \"label\": 0 if source == \"Human\" else 1,  # 0 = Humain, 1 = IA\n",
    "                        \"meta_time_spent_per_word\": extra[\"time_spent_per_word\"],\n",
    "                        \"meta_num_deletions\": extra[\"num_deletions\"],\n",
    "                        \"meta_num_rewrites\": extra[\"num_rewrites\"],\n",
    "                        \"meta_copy_paste_usage\": extra[\"copy_paste_usage\"],\n",
    "                        \"meta_pauses\": extra[\"pauses\"],\n",
    "                        \"meta_sentence_reordering\": extra[\"sentence_reordering\"],\n",
    "                    })\n",
    "\n",
    "# Convertir en DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Séparer les textes et les métadonnées\n",
    "df_meta = df.filter(like=\"meta_\").astype(float)  # Extraire uniquement les colonnes méta\n",
    "\n",
    "print(\"✅ Données chargées avec séparation des métadonnées\")\n",
    "print(df.head())  # Vérifier le DataFrame complet\n",
    "print(df_meta.head())  # Vérifier les métadonnées seules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f33c1246-3cb7-40a5-a428-47b82ad804ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Division en ensembles d'entraînement et de test\n",
    "train_texts, test_texts, train_meta, test_meta, train_labels, test_labels = train_test_split(\n",
    "    df[\"text\"].tolist(), df_meta.values, df[\"label\"].values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Définition du Dataset\n",
    "class TextMetaDataset(Dataset):\n",
    "    def __init__(self, texts, meta, labels):\n",
    "        self.texts = texts\n",
    "        self.meta = torch.tensor(meta, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoding = tokenizer(self.texts[idx], padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        return {\"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "                \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "                \"meta\": self.meta[idx],\n",
    "                \"label\": self.labels[idx]}\n",
    "\n",
    "# Charger les données\n",
    "train_dataset = TextMetaDataset(train_texts, train_meta, train_labels)\n",
    "test_dataset = TextMetaDataset(test_texts, test_meta, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Définition du modèle\n",
    "class TextMetaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextMetaClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.meta_fc = nn.Sequential(\n",
    "            nn.Linear(6, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size + 8, 1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, meta):\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_embedding = bert_output.pooler_output\n",
    "        meta_embedding = self.meta_fc(meta)\n",
    "        combined = torch.cat((text_embedding, meta_embedding), dim=1)\n",
    "        return torch.sigmoid(self.fc(combined))\n",
    "\n",
    "# Initialisation du modèle\n",
    "model = TextMetaClassifier()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "def train_model(model, train_loader, optimizer, criterion, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            input_ids, attention_mask, meta, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"meta\"], batch[\"label\"]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask, meta).squeeze()\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "164cb252-4901-48b4-b97c-0ab339544b9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Division en ensembles d'entraînement et de test\n",
    "train_texts, test_texts, train_meta, test_meta, train_labels, test_labels = train_test_split(\n",
    "    df[\"text\"].tolist(), df_meta.values, df[\"label\"].values, test_size=0.2, random_state=42)\n",
    "\n",
    "#from transformers import BertTokenizer\n",
    "\n",
    "# Définition du Dataset\n",
    "class TextMetaDataset(Dataset):\n",
    "    def __init__(self, texts, meta, labels):\n",
    "        self.texts = texts\n",
    "        self.meta = torch.tensor(meta, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")  # Ajout du tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(self.texts[idx], padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"meta\": self.meta[idx],\n",
    "            \"label\": self.labels[idx]\n",
    "        }\n",
    "\n",
    "# Charger les données\n",
    "train_dataset = TextMetaDataset(train_texts, train_meta, train_labels)\n",
    "test_dataset = TextMetaDataset(test_texts, test_meta, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Définition du modèle\n",
    "class TextMetaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextMetaClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.meta_fc = nn.Sequential(\n",
    "            nn.Linear(6, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size + 8, 1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, meta):\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_embedding = bert_output.pooler_output\n",
    "        meta_embedding = self.meta_fc(meta)\n",
    "        combined = torch.cat((text_embedding, meta_embedding), dim=1)\n",
    "        return torch.sigmoid(self.fc(combined))\n",
    "\n",
    "# Initialisation du modèle\n",
    "model = TextMetaClassifier()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "def train_model(model, train_loader, optimizer, criterion, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            input_ids, attention_mask, meta, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"meta\"], batch[\"label\"]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask, meta).squeeze()\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d72ecc2-1822-48a2-9cc4-ca2898e6ccb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight: cpu\n",
      "bert.embeddings.position_embeddings.weight: cpu\n",
      "bert.embeddings.token_type_embeddings.weight: cpu\n",
      "bert.embeddings.LayerNorm.weight: cpu\n",
      "bert.embeddings.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.0.attention.self.query.weight: cpu\n",
      "bert.encoder.layer.0.attention.self.query.bias: cpu\n",
      "bert.encoder.layer.0.attention.self.key.weight: cpu\n",
      "bert.encoder.layer.0.attention.self.key.bias: cpu\n",
      "bert.encoder.layer.0.attention.self.value.weight: cpu\n",
      "bert.encoder.layer.0.attention.self.value.bias: cpu\n",
      "bert.encoder.layer.0.attention.output.dense.weight: cpu\n",
      "bert.encoder.layer.0.attention.output.dense.bias: cpu\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.0.intermediate.dense.weight: cpu\n",
      "bert.encoder.layer.0.intermediate.dense.bias: cpu\n",
      "bert.encoder.layer.0.output.dense.weight: cpu\n",
      "bert.encoder.layer.0.output.dense.bias: cpu\n",
      "bert.encoder.layer.0.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.0.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.1.attention.self.query.weight: cpu\n",
      "bert.encoder.layer.1.attention.self.query.bias: cpu\n",
      "bert.encoder.layer.1.attention.self.key.weight: cpu\n",
      "bert.encoder.layer.1.attention.self.key.bias: cpu\n",
      "bert.encoder.layer.1.attention.self.value.weight: cpu\n",
      "bert.encoder.layer.1.attention.self.value.bias: cpu\n",
      "bert.encoder.layer.1.attention.output.dense.weight: cpu\n",
      "bert.encoder.layer.1.attention.output.dense.bias: cpu\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.1.intermediate.dense.weight: cpu\n",
      "bert.encoder.layer.1.intermediate.dense.bias: cpu\n",
      "bert.encoder.layer.1.output.dense.weight: cpu\n",
      "bert.encoder.layer.1.output.dense.bias: cpu\n",
      "bert.encoder.layer.1.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.1.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.2.attention.self.query.weight: cpu\n",
      "bert.encoder.layer.2.attention.self.query.bias: cpu\n",
      "bert.encoder.layer.2.attention.self.key.weight: cpu\n",
      "bert.encoder.layer.2.attention.self.key.bias: cpu\n",
      "bert.encoder.layer.2.attention.self.value.weight: cpu\n",
      "bert.encoder.layer.2.attention.self.value.bias: cpu\n",
      "bert.encoder.layer.2.attention.output.dense.weight: cpu\n",
      "bert.encoder.layer.2.attention.output.dense.bias: cpu\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.2.intermediate.dense.weight: cpu\n",
      "bert.encoder.layer.2.intermediate.dense.bias: cpu\n",
      "bert.encoder.layer.2.output.dense.weight: cpu\n",
      "bert.encoder.layer.2.output.dense.bias: cpu\n",
      "bert.encoder.layer.2.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.2.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.3.attention.self.query.weight: cpu\n",
      "bert.encoder.layer.3.attention.self.query.bias: cpu\n",
      "bert.encoder.layer.3.attention.self.key.weight: cpu\n",
      "bert.encoder.layer.3.attention.self.key.bias: cpu\n",
      "bert.encoder.layer.3.attention.self.value.weight: cpu\n",
      "bert.encoder.layer.3.attention.self.value.bias: cpu\n",
      "bert.encoder.layer.3.attention.output.dense.weight: cpu\n",
      "bert.encoder.layer.3.attention.output.dense.bias: cpu\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.3.intermediate.dense.weight: cpu\n",
      "bert.encoder.layer.3.intermediate.dense.bias: cpu\n",
      "bert.encoder.layer.3.output.dense.weight: cpu\n",
      "bert.encoder.layer.3.output.dense.bias: cpu\n",
      "bert.encoder.layer.3.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.3.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.4.attention.self.query.weight: cpu\n",
      "bert.encoder.layer.4.attention.self.query.bias: cpu\n",
      "bert.encoder.layer.4.attention.self.key.weight: cpu\n",
      "bert.encoder.layer.4.attention.self.key.bias: cpu\n",
      "bert.encoder.layer.4.attention.self.value.weight: cpu\n",
      "bert.encoder.layer.4.attention.self.value.bias: cpu\n",
      "bert.encoder.layer.4.attention.output.dense.weight: cpu\n",
      "bert.encoder.layer.4.attention.output.dense.bias: cpu\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.4.intermediate.dense.weight: cpu\n",
      "bert.encoder.layer.4.intermediate.dense.bias: cpu\n",
      "bert.encoder.layer.4.output.dense.weight: cpu\n",
      "bert.encoder.layer.4.output.dense.bias: cpu\n",
      "bert.encoder.layer.4.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.4.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.5.attention.self.query.weight: cpu\n",
      "bert.encoder.layer.5.attention.self.query.bias: cpu\n",
      "bert.encoder.layer.5.attention.self.key.weight: cpu\n",
      "bert.encoder.layer.5.attention.self.key.bias: cpu\n",
      "bert.encoder.layer.5.attention.self.value.weight: cpu\n",
      "bert.encoder.layer.5.attention.self.value.bias: cpu\n",
      "bert.encoder.layer.5.attention.output.dense.weight: cpu\n",
      "bert.encoder.layer.5.attention.output.dense.bias: cpu\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.5.intermediate.dense.weight: cpu\n",
      "bert.encoder.layer.5.intermediate.dense.bias: cpu\n",
      "bert.encoder.layer.5.output.dense.weight: cpu\n",
      "bert.encoder.layer.5.output.dense.bias: cpu\n",
      "bert.encoder.layer.5.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.5.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.6.attention.self.query.weight: cpu\n",
      "bert.encoder.layer.6.attention.self.query.bias: cpu\n",
      "bert.encoder.layer.6.attention.self.key.weight: cpu\n",
      "bert.encoder.layer.6.attention.self.key.bias: cpu\n",
      "bert.encoder.layer.6.attention.self.value.weight: cpu\n",
      "bert.encoder.layer.6.attention.self.value.bias: cpu\n",
      "bert.encoder.layer.6.attention.output.dense.weight: cpu\n",
      "bert.encoder.layer.6.attention.output.dense.bias: cpu\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.6.intermediate.dense.weight: cpu\n",
      "bert.encoder.layer.6.intermediate.dense.bias: cpu\n",
      "bert.encoder.layer.6.output.dense.weight: cpu\n",
      "bert.encoder.layer.6.output.dense.bias: cpu\n",
      "bert.encoder.layer.6.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.6.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.7.attention.self.query.weight: cpu\n",
      "bert.encoder.layer.7.attention.self.query.bias: cpu\n",
      "bert.encoder.layer.7.attention.self.key.weight: cpu\n",
      "bert.encoder.layer.7.attention.self.key.bias: cpu\n",
      "bert.encoder.layer.7.attention.self.value.weight: cpu\n",
      "bert.encoder.layer.7.attention.self.value.bias: cpu\n",
      "bert.encoder.layer.7.attention.output.dense.weight: cpu\n",
      "bert.encoder.layer.7.attention.output.dense.bias: cpu\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.7.intermediate.dense.weight: cpu\n",
      "bert.encoder.layer.7.intermediate.dense.bias: cpu\n",
      "bert.encoder.layer.7.output.dense.weight: cpu\n",
      "bert.encoder.layer.7.output.dense.bias: cpu\n",
      "bert.encoder.layer.7.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.7.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.8.attention.self.query.weight: cpu\n",
      "bert.encoder.layer.8.attention.self.query.bias: cpu\n",
      "bert.encoder.layer.8.attention.self.key.weight: cpu\n",
      "bert.encoder.layer.8.attention.self.key.bias: cpu\n",
      "bert.encoder.layer.8.attention.self.value.weight: cpu\n",
      "bert.encoder.layer.8.attention.self.value.bias: cpu\n",
      "bert.encoder.layer.8.attention.output.dense.weight: cpu\n",
      "bert.encoder.layer.8.attention.output.dense.bias: cpu\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.8.intermediate.dense.weight: cpu\n",
      "bert.encoder.layer.8.intermediate.dense.bias: cpu\n",
      "bert.encoder.layer.8.output.dense.weight: cpu\n",
      "bert.encoder.layer.8.output.dense.bias: cpu\n",
      "bert.encoder.layer.8.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.8.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.9.attention.self.query.weight: cpu\n",
      "bert.encoder.layer.9.attention.self.query.bias: cpu\n",
      "bert.encoder.layer.9.attention.self.key.weight: cpu\n",
      "bert.encoder.layer.9.attention.self.key.bias: cpu\n",
      "bert.encoder.layer.9.attention.self.value.weight: cpu\n",
      "bert.encoder.layer.9.attention.self.value.bias: cpu\n",
      "bert.encoder.layer.9.attention.output.dense.weight: cpu\n",
      "bert.encoder.layer.9.attention.output.dense.bias: cpu\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.9.intermediate.dense.weight: cpu\n",
      "bert.encoder.layer.9.intermediate.dense.bias: cpu\n",
      "bert.encoder.layer.9.output.dense.weight: cpu\n",
      "bert.encoder.layer.9.output.dense.bias: cpu\n",
      "bert.encoder.layer.9.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.9.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.10.attention.self.query.weight: cpu\n",
      "bert.encoder.layer.10.attention.self.query.bias: cpu\n",
      "bert.encoder.layer.10.attention.self.key.weight: cpu\n",
      "bert.encoder.layer.10.attention.self.key.bias: cpu\n",
      "bert.encoder.layer.10.attention.self.value.weight: cpu\n",
      "bert.encoder.layer.10.attention.self.value.bias: cpu\n",
      "bert.encoder.layer.10.attention.output.dense.weight: cpu\n",
      "bert.encoder.layer.10.attention.output.dense.bias: cpu\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.10.intermediate.dense.weight: cpu\n",
      "bert.encoder.layer.10.intermediate.dense.bias: cpu\n",
      "bert.encoder.layer.10.output.dense.weight: cpu\n",
      "bert.encoder.layer.10.output.dense.bias: cpu\n",
      "bert.encoder.layer.10.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.10.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.11.attention.self.query.weight: cpu\n",
      "bert.encoder.layer.11.attention.self.query.bias: cpu\n",
      "bert.encoder.layer.11.attention.self.key.weight: cpu\n",
      "bert.encoder.layer.11.attention.self.key.bias: cpu\n",
      "bert.encoder.layer.11.attention.self.value.weight: cpu\n",
      "bert.encoder.layer.11.attention.self.value.bias: cpu\n",
      "bert.encoder.layer.11.attention.output.dense.weight: cpu\n",
      "bert.encoder.layer.11.attention.output.dense.bias: cpu\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias: cpu\n",
      "bert.encoder.layer.11.intermediate.dense.weight: cpu\n",
      "bert.encoder.layer.11.intermediate.dense.bias: cpu\n",
      "bert.encoder.layer.11.output.dense.weight: cpu\n",
      "bert.encoder.layer.11.output.dense.bias: cpu\n",
      "bert.encoder.layer.11.output.LayerNorm.weight: cpu\n",
      "bert.encoder.layer.11.output.LayerNorm.bias: cpu\n",
      "bert.pooler.dense.weight: cpu\n",
      "bert.pooler.dense.bias: cpu\n",
      "meta_fc.0.weight: cpu\n",
      "meta_fc.0.bias: cpu\n",
      "meta_fc.2.weight: cpu\n",
      "meta_fc.2.bias: cpu\n",
      "fc.weight: cpu\n",
      "fc.bias: cpu\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.device}\")  # Doit afficher \"cuda:0\" ou \"cpu\" partout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1712016-ab58-4b66-8d7a-375e2045e7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT chargé avec succès !\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "print(\"BERT chargé avec succès !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fe5bed8-58ab-411f-8ae9-fedc0f233ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé sur: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_923/1004896100.py:38: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Accélère l'inférence sur GPU\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, F1-score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Exécuter l'évaluation sans les métadonnées avec optimisation\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[43mevaluate_model_without_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 39\u001b[0m, in \u001b[0;36mevaluate_model_without_meta\u001b[0;34m(model, test_loader, criterion, max_batches)\u001b[0m\n\u001b[1;32m     32\u001b[0m input_ids, attention_mask, labels \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     33\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     34\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     35\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():  \u001b[38;5;66;03m# Accélère l'inférence sur GPU\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpooler_output\n\u001b[1;32m     40\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc(outputs)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     41\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1078\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1076\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m-> 1078\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1087\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((batch_size, seq_length \u001b[38;5;241m+\u001b[39m past_key_values_length), device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    208\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[1;32m    214\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Définition du device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Modèle chargé sur: {device}\")\n",
    "\n",
    "# Mise à jour de la batch size pour accélérer l'évaluation\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Fonction d'évaluation sans les métadonnées\n",
    "def evaluate_model_without_meta(model, test_loader, criterion, max_batches=10):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            if i >= max_batches:\n",
    "                break  # Arrêter l'évaluation après 'max_batches' batchs\n",
    "            \n",
    "            input_ids, attention_mask, labels = (\n",
    "                batch[\"input_ids\"].to(device),\n",
    "                batch[\"attention_mask\"].to(device),\n",
    "                batch[\"label\"].to(device),\n",
    "            )\n",
    "\n",
    "            with autocast():  # Accélère l'inférence sur GPU\n",
    "                outputs = model.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
    "                outputs = model.fc(outputs).squeeze()\n",
    "                loss = criterion(outputs, labels.float())\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = (outputs >= 0.5).long()\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "            \n",
    "            print(f\"Batch {i+1}/{max_batches} - Loss: {loss.item():.4f}\")  # Suivi de l'évaluation\n",
    "    \n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    \n",
    "    avg_loss = total_loss / max_batches\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"✅ Validation Loss (sans métadonnées): {avg_loss:.4f}\")\n",
    "    print(f\"✅ Accuracy (sans métadonnées): {accuracy:.4f}\")\n",
    "    print(f\"✅ Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "# Exécuter l'évaluation sans les métadonnées avec optimisation\n",
    "evaluate_model_without_meta(model, test_loader, criterion, max_batches=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5ecea28-17c1-4fa4-aff9-39c3a1da3659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé sur: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_923/2266101186.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Accélère l'inférence sur GPU\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x768 and 776x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, F1-score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Exécuter l'évaluation sans les métadonnées avec optimisation\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43mevaluate_model_without_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 41\u001b[0m, in \u001b[0;36mevaluate_model_without_meta\u001b[0;34m(model, test_loader, criterion, max_batches)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():  \u001b[38;5;66;03m# Accélère l'inférence sur GPU\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbert(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\u001b[38;5;241m.\u001b[39mpooler_output\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 41\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     42\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     44\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x768 and 776x1)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Définition du device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Modèle chargé sur: {device}\")\n",
    "\n",
    "# Mise à jour de la batch size pour accélérer l'évaluation\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Fonction d'évaluation sans les métadonnées\n",
    "def evaluate_model_without_meta(model, test_loader, criterion, max_batches=10):\n",
    "    model.to(device)  # Assurer que le modèle est bien sur le bon device\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            if i >= max_batches:\n",
    "                break  # Arrêter l'évaluation après 'max_batches' batchs\n",
    "            \n",
    "            input_ids, attention_mask, labels = (\n",
    "                batch[\"input_ids\"].to(device),\n",
    "                batch[\"attention_mask\"].to(device),\n",
    "                batch[\"label\"].to(device),\n",
    "            )\n",
    "\n",
    "            with autocast():  # Accélère l'inférence sur GPU\n",
    "                outputs = model.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output.to(device)\n",
    "                outputs = model.fc(outputs).squeeze().to(device)\n",
    "                loss = criterion(outputs, labels.float())\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = (outputs >= 0.5).long()\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "            \n",
    "            print(f\"Batch {i+1}/{max_batches} - Loss: {loss.item():.4f}\")  # Suivi de l'évaluation\n",
    "    \n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    \n",
    "    avg_loss = total_loss / max_batches\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"✅ Validation Loss (sans métadonnées): {avg_loss:.4f}\")\n",
    "    print(f\"✅ Accuracy (sans métadonnées): {accuracy:.4f}\")\n",
    "    print(f\"✅ Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "# Exécuter l'évaluation sans les métadonnées avec optimisation\n",
    "evaluate_model_without_meta(model, test_loader, criterion, max_batches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc1ef2-d853-4814-9581-9e584ff5e294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 0.6796258687973022\n"
     ]
    }
   ],
   "source": [
    "# Réduction du dataset pour un entraînement rapide\n",
    "df = df.sample(n=5000, random_state=42)\n",
    "df_meta = df.filter(like=\"meta_\").astype(float)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "train_texts, test_texts, train_meta, test_meta, train_labels, test_labels = train_test_split(\n",
    "    df[\"text\"].tolist(), df_meta.values, df[\"label\"].values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Définition du Dataset\n",
    "class TextMetaDataset(Dataset):\n",
    "    def __init__(self, texts, meta, labels):\n",
    "        self.texts = texts\n",
    "        self.meta = torch.tensor(meta, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(self.texts[idx], padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"meta\": self.meta[idx],\n",
    "            \"label\": self.labels[idx]\n",
    "        }\n",
    "\n",
    "# Charger les données\n",
    "train_dataset = TextMetaDataset(train_texts, train_meta, train_labels)\n",
    "test_dataset = TextMetaDataset(test_texts, test_meta, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Définition du modèle\n",
    "class TextMetaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextMetaClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.meta_fc = nn.Sequential(\n",
    "            nn.Linear(6, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size + 8, 1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, meta):\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_embedding = bert_output.pooler_output\n",
    "        meta_embedding = self.meta_fc(meta)\n",
    "        combined = torch.cat((text_embedding, meta_embedding), dim=1)\n",
    "        return torch.sigmoid(self.fc(combined))\n",
    "\n",
    "# Initialisation du modèle\n",
    "model = TextMetaClassifier()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Fonction de sauvegarde et chargement des checkpoints\n",
    "def save_checkpoint(epoch, model, optimizer, loss, path=\"checkpoint.pth\"):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, path)\n",
    "    print(f\"✅ Modèle sauvegardé après l'epoch {epoch}\")\n",
    "\n",
    "def train_model(model, train_loader, optimizer, criterion, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            input_ids, attention_mask, meta, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"meta\"], batch[\"label\"]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask, meta).squeeze()\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 0:  # Affichage toutes les 10 itérations\n",
    "                print(f\"Epoch {epoch + 1}, Batch {i}, Loss: {loss.item()}\")\n",
    "        print(f\"Epoch {epoch + 1} terminé, Loss Moyenne: {running_loss / len(train_loader)}\")\n",
    "        save_checkpoint(epoch, model, optimizer, running_loss / len(train_loader))\n",
    "\n",
    "train_model(model, train_loader, optimizer, criterion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eecedf4-26f4-4c0c-8943-c9f3de97da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "# Définition du device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids, attention_mask, meta, labels = (\n",
    "                batch[\"input_ids\"].to(device),\n",
    "                batch[\"attention_mask\"].to(device),\n",
    "                batch[\"meta\"].to(device),\n",
    "                batch[\"label\"].to(device),\n",
    "            )\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, meta).squeeze()\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = (outputs >= 0.5).long()  # Seuil de classification\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"✅ Validation Loss: {avg_loss:.4f}\")\n",
    "    print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"✅ Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "# Exécuter l'évaluation\n",
    "evaluate_model(model, test_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c724db3b-da74-4e7d-b5c9-0ed2aa963be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/250 - Loss: 0.3057\n",
      "Batch 2/250 - Loss: 0.0052\n",
      "Batch 3/250 - Loss: 0.1583\n",
      "Batch 4/250 - Loss: 0.0033\n",
      "Batch 5/250 - Loss: 0.0024\n",
      "Batch 6/250 - Loss: 0.0101\n",
      "Batch 7/250 - Loss: 0.0220\n",
      "Batch 8/250 - Loss: 0.0030\n",
      "Batch 9/250 - Loss: 0.9458\n",
      "Batch 10/250 - Loss: 0.0010\n",
      "Batch 11/250 - Loss: 0.9965\n",
      "Batch 12/250 - Loss: 0.0019\n",
      "Batch 13/250 - Loss: 0.0006\n",
      "Batch 14/250 - Loss: 0.0070\n",
      "Batch 15/250 - Loss: 0.3241\n",
      "Batch 16/250 - Loss: 0.0030\n",
      "Batch 17/250 - Loss: 0.0106\n",
      "Batch 18/250 - Loss: 0.0043\n",
      "Batch 19/250 - Loss: 0.0010\n",
      "Batch 20/250 - Loss: 0.0044\n",
      "Batch 21/250 - Loss: 0.6886\n",
      "Batch 22/250 - Loss: 0.0032\n",
      "Batch 23/250 - Loss: 0.6866\n",
      "Batch 24/250 - Loss: 0.2109\n",
      "Batch 25/250 - Loss: 0.0673\n",
      "Batch 26/250 - Loss: 0.0155\n",
      "Batch 27/250 - Loss: 0.1304\n",
      "Batch 28/250 - Loss: 0.0048\n",
      "Batch 29/250 - Loss: 0.0223\n",
      "Batch 30/250 - Loss: 0.0041\n",
      "Batch 31/250 - Loss: 0.0031\n",
      "Batch 32/250 - Loss: 0.0031\n",
      "Batch 33/250 - Loss: 0.0009\n",
      "Batch 34/250 - Loss: 0.0050\n",
      "Batch 35/250 - Loss: 0.0016\n",
      "Batch 36/250 - Loss: 0.0076\n",
      "Batch 37/250 - Loss: 0.8073\n",
      "Batch 38/250 - Loss: 0.7435\n",
      "Batch 39/250 - Loss: 1.0463\n",
      "Batch 40/250 - Loss: 0.0028\n",
      "Batch 41/250 - Loss: 0.0016\n",
      "Batch 42/250 - Loss: 0.0043\n",
      "Batch 43/250 - Loss: 0.0050\n",
      "Batch 44/250 - Loss: 0.0006\n",
      "Batch 45/250 - Loss: 0.0043\n",
      "Batch 46/250 - Loss: 0.0078\n",
      "Batch 47/250 - Loss: 0.0629\n",
      "Batch 48/250 - Loss: 0.0091\n",
      "Batch 49/250 - Loss: 0.0487\n",
      "Batch 50/250 - Loss: 0.0006\n",
      "Batch 51/250 - Loss: 1.1203\n",
      "Batch 52/250 - Loss: 0.0084\n",
      "Batch 53/250 - Loss: 0.0031\n",
      "Batch 54/250 - Loss: 0.0065\n",
      "Batch 55/250 - Loss: 0.0305\n",
      "Batch 56/250 - Loss: 0.0064\n",
      "Batch 57/250 - Loss: 0.0219\n",
      "Batch 58/250 - Loss: 0.0053\n",
      "Batch 59/250 - Loss: 0.0060\n",
      "Batch 60/250 - Loss: 0.0018\n",
      "Batch 61/250 - Loss: 0.0046\n",
      "Batch 62/250 - Loss: 0.1702\n",
      "Batch 63/250 - Loss: 0.7018\n",
      "Batch 64/250 - Loss: 0.0256\n",
      "Batch 65/250 - Loss: 0.0271\n",
      "Batch 66/250 - Loss: 0.9378\n",
      "Batch 67/250 - Loss: 0.0031\n",
      "Batch 68/250 - Loss: 0.0009\n",
      "Batch 69/250 - Loss: 0.1294\n",
      "Batch 70/250 - Loss: 0.0068\n",
      "Batch 71/250 - Loss: 0.0033\n",
      "Batch 72/250 - Loss: 0.1315\n",
      "Batch 73/250 - Loss: 0.0131\n",
      "Batch 74/250 - Loss: 0.1250\n",
      "Batch 75/250 - Loss: 0.0512\n",
      "Batch 76/250 - Loss: 0.0213\n",
      "Batch 77/250 - Loss: 0.0042\n",
      "Batch 78/250 - Loss: 0.0038\n",
      "Batch 79/250 - Loss: 0.0115\n",
      "Batch 80/250 - Loss: 0.3521\n",
      "Batch 81/250 - Loss: 0.0006\n",
      "Batch 82/250 - Loss: 0.0022\n",
      "Batch 83/250 - Loss: 0.5265\n",
      "Batch 84/250 - Loss: 0.0065\n",
      "Batch 85/250 - Loss: 0.5652\n",
      "Batch 86/250 - Loss: 0.0110\n",
      "Batch 87/250 - Loss: 0.0356\n",
      "Batch 88/250 - Loss: 0.0050\n",
      "Batch 89/250 - Loss: 0.0014\n",
      "Batch 90/250 - Loss: 0.0113\n",
      "Batch 91/250 - Loss: 0.0020\n",
      "Batch 92/250 - Loss: 0.0055\n",
      "Batch 93/250 - Loss: 0.0507\n",
      "Batch 94/250 - Loss: 0.0150\n",
      "Batch 95/250 - Loss: 0.0012\n",
      "Batch 96/250 - Loss: 0.3231\n",
      "Batch 97/250 - Loss: 0.8668\n",
      "Batch 98/250 - Loss: 0.0029\n",
      "Batch 99/250 - Loss: 0.0011\n",
      "Batch 100/250 - Loss: 0.0063\n",
      "Batch 101/250 - Loss: 0.0073\n",
      "Batch 102/250 - Loss: 0.0220\n",
      "Batch 103/250 - Loss: 0.0051\n",
      "Batch 104/250 - Loss: 0.0195\n",
      "Batch 105/250 - Loss: 0.0041\n",
      "Batch 106/250 - Loss: 0.0033\n",
      "Batch 107/250 - Loss: 0.0013\n",
      "Batch 108/250 - Loss: 0.0014\n",
      "Batch 109/250 - Loss: 0.0119\n",
      "Batch 110/250 - Loss: 0.5730\n",
      "Batch 111/250 - Loss: 0.0056\n",
      "Batch 112/250 - Loss: 0.0087\n",
      "Batch 113/250 - Loss: 0.0013\n",
      "Batch 114/250 - Loss: 0.0228\n",
      "Batch 115/250 - Loss: 0.0322\n",
      "Batch 116/250 - Loss: 0.0212\n",
      "Batch 117/250 - Loss: 0.0014\n",
      "Batch 118/250 - Loss: 0.0050\n",
      "Batch 119/250 - Loss: 1.1010\n",
      "Batch 120/250 - Loss: 0.0020\n",
      "Batch 121/250 - Loss: 0.0045\n",
      "Batch 122/250 - Loss: 0.0403\n",
      "Batch 123/250 - Loss: 0.5499\n",
      "Batch 124/250 - Loss: 0.0093\n",
      "Batch 125/250 - Loss: 0.0006\n",
      "Batch 126/250 - Loss: 0.0057\n",
      "Batch 127/250 - Loss: 0.0162\n",
      "Batch 128/250 - Loss: 0.0030\n",
      "Batch 129/250 - Loss: 0.0037\n",
      "Batch 130/250 - Loss: 0.0190\n",
      "Batch 131/250 - Loss: 0.0089\n",
      "Batch 132/250 - Loss: 0.0068\n",
      "Batch 133/250 - Loss: 0.0080\n",
      "Batch 134/250 - Loss: 0.0186\n",
      "Batch 135/250 - Loss: 0.0352\n",
      "Batch 136/250 - Loss: 0.0019\n",
      "Batch 137/250 - Loss: 0.0104\n",
      "Batch 138/250 - Loss: 0.0067\n",
      "Batch 139/250 - Loss: 0.0015\n",
      "Batch 140/250 - Loss: 0.0082\n",
      "Batch 141/250 - Loss: 0.0277\n",
      "Batch 142/250 - Loss: 0.0005\n",
      "Batch 143/250 - Loss: 0.0205\n",
      "Batch 144/250 - Loss: 0.0006\n",
      "Batch 145/250 - Loss: 0.0042\n",
      "Batch 146/250 - Loss: 0.0176\n",
      "Batch 147/250 - Loss: 0.3324\n",
      "Batch 148/250 - Loss: 0.0038\n",
      "Batch 149/250 - Loss: 0.0037\n",
      "Batch 150/250 - Loss: 0.0109\n",
      "Batch 151/250 - Loss: 0.0008\n",
      "Batch 152/250 - Loss: 0.0149\n",
      "Batch 153/250 - Loss: 0.0048\n",
      "Batch 154/250 - Loss: 0.0022\n",
      "Batch 155/250 - Loss: 0.0254\n",
      "Batch 156/250 - Loss: 0.0055\n",
      "Batch 157/250 - Loss: 0.0023\n",
      "Batch 158/250 - Loss: 0.0076\n",
      "Batch 159/250 - Loss: 0.0016\n",
      "Batch 160/250 - Loss: 0.0043\n",
      "Batch 161/250 - Loss: 0.0005\n",
      "Batch 162/250 - Loss: 0.0184\n",
      "Batch 163/250 - Loss: 0.0071\n",
      "Batch 164/250 - Loss: 0.0057\n",
      "Batch 165/250 - Loss: 0.0113\n",
      "Batch 166/250 - Loss: 0.0057\n",
      "Batch 167/250 - Loss: 0.0032\n",
      "Batch 168/250 - Loss: 0.0292\n",
      "Batch 169/250 - Loss: 0.0032\n",
      "Batch 170/250 - Loss: 0.7730\n",
      "Batch 171/250 - Loss: 0.0034\n",
      "Batch 172/250 - Loss: 0.0021\n",
      "Batch 173/250 - Loss: 0.0031\n",
      "Batch 174/250 - Loss: 0.2007\n",
      "Batch 175/250 - Loss: 0.0070\n",
      "Batch 176/250 - Loss: 0.0007\n",
      "Batch 177/250 - Loss: 0.0005\n",
      "Batch 178/250 - Loss: 0.0075\n",
      "Batch 179/250 - Loss: 0.0109\n",
      "Batch 180/250 - Loss: 0.0043\n",
      "Batch 181/250 - Loss: 0.0318\n",
      "Batch 182/250 - Loss: 0.0017\n",
      "Batch 183/250 - Loss: 0.0063\n",
      "Batch 184/250 - Loss: 0.1330\n",
      "Batch 185/250 - Loss: 0.9443\n",
      "Batch 186/250 - Loss: 0.0047\n",
      "Batch 187/250 - Loss: 0.0105\n",
      "Batch 188/250 - Loss: 0.0394\n",
      "Batch 189/250 - Loss: 0.0023\n",
      "Batch 190/250 - Loss: 1.1156\n",
      "Batch 191/250 - Loss: 0.0049\n",
      "Batch 192/250 - Loss: 0.0007\n",
      "Batch 193/250 - Loss: 0.0034\n",
      "Batch 194/250 - Loss: 0.0023\n",
      "Batch 195/250 - Loss: 0.0067\n",
      "Batch 196/250 - Loss: 0.0161\n",
      "Batch 197/250 - Loss: 0.0043\n",
      "Batch 198/250 - Loss: 0.0040\n",
      "Batch 199/250 - Loss: 0.7550\n",
      "Batch 200/250 - Loss: 0.0353\n",
      "Batch 201/250 - Loss: 0.0596\n",
      "Batch 202/250 - Loss: 0.0027\n",
      "Batch 203/250 - Loss: 0.0018\n",
      "Batch 204/250 - Loss: 0.0036\n",
      "Batch 205/250 - Loss: 0.0009\n",
      "Batch 206/250 - Loss: 0.0033\n",
      "Batch 207/250 - Loss: 0.0103\n",
      "Batch 208/250 - Loss: 0.0034\n",
      "Batch 209/250 - Loss: 0.0055\n",
      "Batch 210/250 - Loss: 0.0024\n",
      "Batch 211/250 - Loss: 0.0157\n",
      "Batch 212/250 - Loss: 0.0064\n",
      "Batch 213/250 - Loss: 0.0026\n",
      "Batch 214/250 - Loss: 0.0135\n",
      "Batch 215/250 - Loss: 0.4752\n",
      "Batch 216/250 - Loss: 0.3880\n",
      "Batch 217/250 - Loss: 0.0457\n",
      "Batch 218/250 - Loss: 0.0094\n",
      "Batch 219/250 - Loss: 0.0028\n",
      "Batch 220/250 - Loss: 0.3611\n",
      "Batch 221/250 - Loss: 1.5052\n",
      "Batch 222/250 - Loss: 0.0061\n",
      "Batch 223/250 - Loss: 0.0139\n",
      "Batch 224/250 - Loss: 0.0027\n",
      "Batch 225/250 - Loss: 0.7117\n",
      "Batch 226/250 - Loss: 0.7854\n",
      "Batch 227/250 - Loss: 0.7483\n",
      "Batch 228/250 - Loss: 0.0055\n",
      "Batch 229/250 - Loss: 0.0085\n",
      "Batch 230/250 - Loss: 0.0043\n",
      "Batch 231/250 - Loss: 0.1134\n",
      "Batch 232/250 - Loss: 0.0046\n",
      "Batch 233/250 - Loss: 0.0023\n",
      "Batch 234/250 - Loss: 0.0968\n",
      "Batch 235/250 - Loss: 0.1180\n",
      "Batch 236/250 - Loss: 0.0040\n",
      "Batch 237/250 - Loss: 0.0052\n",
      "Batch 238/250 - Loss: 0.2029\n",
      "Batch 239/250 - Loss: 0.0546\n",
      "Batch 240/250 - Loss: 0.0041\n",
      "Batch 241/250 - Loss: 0.0533\n",
      "Batch 242/250 - Loss: 0.0051\n",
      "Batch 243/250 - Loss: 0.1026\n",
      "Batch 244/250 - Loss: 0.1038\n",
      "Batch 245/250 - Loss: 0.0168\n",
      "Batch 246/250 - Loss: 0.0037\n",
      "Batch 247/250 - Loss: 0.0080\n",
      "Batch 248/250 - Loss: 0.4634\n",
      "Batch 249/250 - Loss: 0.0063\n",
      "Batch 250/250 - Loss: 0.0050\n",
      "✅ Validation Loss: 0.1107\n",
      "✅ Accuracy: 0.9630\n",
      "✅ Precision: 0.9467, Recall: 0.9440, F1-score: 0.9453\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Définition du device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Réduction de l'échantillon de test pour accélérer l'évaluation\n",
    "test_subset_size = min(100, len(test_loader.dataset))  # Limite à 100 échantillons max\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Fonction d'évaluation\n",
    "def evaluate_model(model, test_loader, criterion, max_batches=250):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            if i >= max_batches:\n",
    "                break  # Arrêter l'évaluation après 'max_batches' batchs\n",
    "            \n",
    "            input_ids, attention_mask, meta, labels = (\n",
    "                batch[\"input_ids\"].to(device),\n",
    "                batch[\"attention_mask\"].to(device),\n",
    "                batch[\"meta\"].to(device),\n",
    "                batch[\"label\"].to(device),\n",
    "            )\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, meta).squeeze()\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = (outputs >= 0.5).long()\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "            \n",
    "            print(f\"Batch {i+1}/{max_batches} - Loss: {loss.item():.4f}\")  # Suivi de l'évaluation\n",
    "    \n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    \n",
    "    avg_loss = total_loss / max_batches\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"✅ Validation Loss: {avg_loss:.4f}\")\n",
    "    print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"✅ Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "# Exécuter l'évaluation avec un échantillon réduit\n",
    "evaluate_model(model, test_loader, criterion, max_batches=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddb4eb2-9288-4574-a8aa-24f9c6a1c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Définition du device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Utilisation de {device}\")\n",
    "\n",
    "# Charger le modèle\n",
    "model = TextMetaClassifier().to(device)  # Met le modèle sur le bon device\n",
    "checkpoint = torch.load(\"checkpoint.pth\", map_location=device)  # Charge sur le bon device\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "# Restaurer l'optimiseur sur le bon device\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "# Déplacer les valeurs de l'optimiseur vers le bon device\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['params'] = [p.to(device) for p in param_group['params']]\n",
    "\n",
    "print(f\"✅ Modèle restauré à l'epoch {checkpoint['epoch']} avec loss {checkpoint['loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa634f-bf79-44a2-a5fa-2610354c375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Charger le modèle\n",
    "model = TextMetaClassifier()\n",
    "checkpoint = torch.load(\"checkpoint.pth\", map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "# Restaurer l'optimiseur\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "print(f\"✅ Modèle restauré à l'epoch {checkpoint['epoch']} avec loss {checkpoint['loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca1379ce-b91f-4c84-b7e5-cfa0c3e37d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.29.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdf527fe-6487-4196-9482-553ea33892da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31358532-880e-4970-acf3-f088043471f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3350539c-6306-4076-8c41-c6fa6634c914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (2.2.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.17.0)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.29.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.29.2-py3-none-any.whl (468 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: tzdata, threadpoolctl, scipy, safetensors, regex, joblib, scikit-learn, pandas, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.29.2 joblib-1.4.2 pandas-2.2.3 regex-2024.11.6 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.5.0 tokenizers-0.21.0 transformers-4.49.0 tzdata-2025.1\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn pandas transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e060d-b5c5-467a-b90a-7ba87e373618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
